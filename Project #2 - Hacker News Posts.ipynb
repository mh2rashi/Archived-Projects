{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Popular Hacker News Posts\n",
    "\n",
    "This project analyzes a kaggle dataset to find what kind of posts recieve more comments on average on the popular technology website Hacker News. Hacker News is a website where users submit posts which are voted and commented upon. Similar to reddit, posts that make it to the top can get thousands of visitors. We will be exploring posts that begin with \"Ask HN\" (posts for asking questions) or \"Show HN\"(posts for showing projects, or something else) and analyze if they recieve more comments on average. Also, we will be analyzing if posts created at a certain time recieve more comments on average.\n",
    "\n",
    "\n",
    "## Concepts Used\n",
    "\n",
    "* The basics of programming in Python (arithmetical operations, variables, common data types, etc.)\n",
    "* Jupyter Notebook\n",
    "* Working with Strings\n",
    "* Object-oriented programming\n",
    "* Dates and times\n",
    "* List and for loops\n",
    "* Conditional statements\n",
    "* Dictionaries\n",
    "* Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The dataset contains information on Hacker News posts for a 12 month period (up to September 26, 2016).\n",
    "\n",
    "[Hacker News Posts](https://www.kaggle.com/hacker-news/hacker-news-posts): The dataset has been reduced from almost 300,000 to approximately 20,000 rows by removing submissions that didn't recieve any comments and randomly sampling from the remaining submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "We will load the dataset and look at the first couple of rows. We will also print, describe and identify columns that can help us with our anlaysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "Number of rows: 20101\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "### Hacker News Dataset ###\n",
    "\n",
    "file = open(\"hacker_news.csv\")\n",
    "hacker_news = reader(file)\n",
    "hn = list(hacker_news)\n",
    "\n",
    "for row in hn[:5]:\n",
    "    print(row)\n",
    "    print('\\n')\n",
    "    \n",
    "print('Number of rows:', len(hn))\n",
    "print('Number of columns:', len(hn[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hn dataset, we have data describing 20100 posts (first row is for the header) with 7 columns. Here's a description for each of the columns from the Kaggle website.\n",
    "\n",
    "\n",
    "* \"title\": title of the post (self explanatory)\n",
    "\n",
    "* \"url\": the url of the item being linked to\n",
    "\n",
    "* \"num_points\": the number of upvotes the post received\n",
    "\n",
    "* \"num_comments\": the number of comments the post received\n",
    "\n",
    "* \"author\": the name of the account that made the post\n",
    "\n",
    "* \"created_at\": the date and time the post was made (the time zone is Eastern Time in the US)* \n",
    "\n",
    "At first glance, `title`, `num_points`, `num_comments`, and `created_at` seem to be the most useful comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractring the header row\n",
    "\n",
    "hn_header = hn[0]\n",
    "\n",
    "# Removing the header row form our dataset\n",
    "\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis: Ask HN and Show HN Posts\n",
    "\n",
    "* Since we want to analyze **Ask HN** and **Show HN** posts, we will create two lists which contain each.\n",
    "\n",
    "* We will also display a couple rows for each of the new lists.\n",
    "\n",
    "* Then we will calculate the average number of comments for **ASK HN** and **Show HN** lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of ASK HN posts: 1744\n",
      "\n",
      "\n",
      "# of SHOW HN posts: 1162\n",
      "\n",
      "\n",
      "# of OTHER posts: 17194\n",
      "\n",
      "\n",
      "ASK HN Posts\n",
      "\n",
      "\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "\n",
      "\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "\n",
      "\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n",
      "\n",
      "\n",
      "SHOW HN Posts\n",
      "\n",
      "\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "\n",
      "\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "\n",
      "\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a for loop to extracte posts based on title\n",
    "\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"# of ASK HN posts:\",len(ask_posts))\n",
    "print('\\n')\n",
    "print(\"# of SHOW HN posts:\",len(show_posts))\n",
    "print('\\n')\n",
    "print(\"# of OTHER posts:\",len(other_posts))\n",
    "print('\\n')\n",
    "\n",
    "print(\"ASK HN Posts\")\n",
    "print('\\n')\n",
    "for row in ask_posts[:5]:\n",
    "    print(row)\n",
    "    print('\\n')\n",
    "\n",
    "print(\"SHOW HN Posts\")\n",
    "print('\\n')\n",
    "for row in show_posts[:5]:\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the average number of comments for Ask HN and Show HN posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Comments Average:14.038417431192661\n",
      "Show Comments Average:10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "comment_numbers = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    comments = int(post[4])\n",
    "    comment_numbers += 1\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/comment_numbers\n",
    "print(\"Ask Comments Average:\" + str(avg_ask_comments))\n",
    "\n",
    "total_show_comments = 0\n",
    "comment_show_total = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    comments = int(post[4])\n",
    "    comment_show_total += 1\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/comment_show_total\n",
    "print(\"Show Comments Average:\" + str(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask posts recieve 4 more comments on average compared to Show posts. We'll focus our analysis only on these posts. We'll check if the post creation time has an effect on comment numbers by creating two dictionaries:\n",
    "\n",
    "* 'counts_by_hour': containing the number of ask posts created during each hour of the day.\n",
    "\n",
    "* 'comments_by_hour': containing the corresponding number of comments ask posts created at each hour recieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Posts created according to each hour\n",
      "\n",
      "\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "Comments recieved according to each hour\n",
      "\n",
      "\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    n_comments = int(post[4])\n",
    "    result_list.append([created_at, n_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for item in result_list:\n",
    "    dt_object = dt.datetime.strptime(item[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(dt_object,\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = item[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += item[1] \n",
    "\n",
    "print(\"Ask Posts created according to each hour\")\n",
    "print('\\n')\n",
    "print(counts_by_hour)\n",
    "print('\\n')\n",
    "print(\"Comments recieved according to each hour\")\n",
    "print('\\n')\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will display the average number of comments per post according to hour. This will help us determine if we can maximize the comments a post recieves if we create it at a certain time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for comment in comments_by_hour:\n",
    "    avg_by_hour.append([comment,comments_by_hour[comment]/counts_by_hour[comment]])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll finish by sorting the list of lists and print the five highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "\n",
      "\n",
      "15:00: 38.59 coments per post\n",
      "\n",
      "\n",
      "02:00: 23.81 coments per post\n",
      "\n",
      "\n",
      "20:00: 21.52 coments per post\n",
      "\n",
      "\n",
      "16:00: 16.80 coments per post\n",
      "\n",
      "\n",
      "21:00: 16.01 coments per post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "print(swap_avg_by_hour)\n",
    "print('\\n')\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "print('\\n')\n",
    "\n",
    "for item in sorted_swap[:5]:\n",
    "    output = \"{time}: {average:.2f} coments per post\"\n",
    "    time = dt.datetime.strptime(item[1],\"%H\")\n",
    "    time_update = dt.datetime.strftime(time,\"%H:%M\")\n",
    "    print(output.format(time=time_update,average=item[0]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset was recorded using the Eastern Time Zone in the US, which is followed in my city - Toronto, Canada. So the best time to achieve more comments would be 3pm in the afternoon.\n",
    "\n",
    "It is worth noting that the dataset we analyzed excluded posts which had 0 comments. So, it would be appropriate to say that of the ASK posts that recieved comments, posts created at 3pm est recieved the most comments on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
